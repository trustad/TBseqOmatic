{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "body {\n",
    "        font-family: \"Monaco\", sans-serif;\n",
    "}\n",
    "</style> \n",
    "# Sherman lab RNAseq analysis pipeline\n",
    "_by Tige Rustad\n",
    "    Senior Scientist in the lab of David Sherman at SCRI\n",
    "    Affiliate Assistant Professor in the UW Dept. of Global Health_\n",
    "\n",
    "## Why use a Jupyter notebook\n",
    "\n",
    "\n",
    "The purpose of this notebook is to walk through the analysis of RNAseq data for a paper I'm working on. Initially this Jupyter notebook was for me alone, a way for me to keep the code and notes for this bit of analysis organized. Then realized I could share this with people in our lab, David in particular, who might get a lot of insight from reading a Jupyter style notebook. I like the way I can walk you through my notes, methods, and the resulting tables and figures all in a single narrative. You can also try making changes to the code on the fly with no coding experience. \n",
    "\n",
    "Finally I realized I might be able to make this more broadly useful to the TB field, so I'm going to try to write this so that it is comprehensible to a general audience. \n",
    "\n",
    "I have taken this notebook and posted it to myBinder.com so that anyone can use it without having to install _anything_ on their computer other than an internet browser. That is so cool. You can also share this notebook with anyone who has Anaconda installed on their computer, so here are additional installation steps for users running this locally (instead of just looking at the contents on nbviewer or running it from myBinder.com).\n",
    "\n",
    "You will need to to do the following steps:\n",
    "1. Install the __[Anaconda python distribution](https://www.anaconda.com/distribution/)__. This will let you run all of the python scripts, pre-installs the most popular Python libraries, provides Jupyter notebook support, and, like BioConductor for R, is curated to maintain stability.\n",
    "2. Install the Clustergrammer 'widget' so we can generate interactive heatmaps/dendograms.\n",
    "    - First run the 'Anaconda prompt' to open a window where we can install new libraries\n",
    "    - Then run the following commands:\n",
    "        -  conda install -c conda-forge ipywidgets\n",
    "        -  pip install --upgrade clustergrammer_widget\n",
    "        -  jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "        -  jupyter nbextension enable --py --sys-prefix clustergrammer_widget\n",
    "3. The big one. This notebook is designed to be used with __[tidy datasets](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)__. That means each row is a different observation, in this case an RNAseq run, and each column is a different variable, here either the expression for a given gene or a column of metadata. \n",
    "\n",
    " ***\n",
    "This version of the notebook is focused on presenting the data from a specific experiment. \n",
    "I think I can make this more generally useful, a really Plug-n-Play RNAseq analysis pipeline that\n",
    "can take any log-normal distributed type of data and get a good first pass understanding of what the data tells you.\n",
    "Making that more generic tool will take more time, but if I seem to being doing things in a round-about fashion, \n",
    "that may be why.\n",
    " \n",
    "I'm going to assume you know how to use Jupyter notebooks. If not, there are many good [basic intros to Jupyter notebooks](http://lmgtfy.com/?q=github+getting+started) on YouTube. \n",
    "***\n",
    "This notebook was inspired by the excellent walkthrough of Seaborn plotting __[here](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)__ and the __[Zika virus notebook](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4972086/)__ from the Ma'ayan lab, and when possible I simply borrowed code from those examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Experimental design](#Experimental-design)\n",
    "2. [Install](#Python-setup) python libraries\n",
    "3. [Data import](#Data-import) and subtable generation\n",
    "4. Set up [color palettes](#Colors)\n",
    "5. Compare data to design- [sanity check](#Sanity-check)\n",
    " -  Clustergrammer of all samples or with replicates merged\n",
    " -  PCA plot of sample types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Experimental design'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental design\n",
    "\n",
    "These data come from an experiment testing the transcriptional impact of perturbing specific transcription factors of _Mycobacerium tuberculosis_ (Mtb), specifically in the context of a hypoxic time course. Oxygen limitation is an environmental stress that arrests growth, alters the drug susceptibility profile, and leads to a complex remodeling of the transcriptome that changes the expression of the majority of the Mtb genes. Hypoxia, or oxygen limitation, is a common in vitro model of Mtb in the latent phase of infection. \n",
    "\n",
    "A prior screen of all of the Mtb transcription factors (TFs) by us identified six TFs that were impaired in their ability to return to active growth when oxygen is returned after 7 days of hypoxia. We have dubbed this set of TFs the Critical Oxygen Response Regulators, or CORRs. \n",
    "\n",
    "#### Dataset variables\n",
    "\n",
    " - Strains: Each strain is carrying the same TF overexpression plasmid with the only difference being the insert\n",
    "    - Rv0023  - a previously undescribed TF that triggers many of the expression changes triggered by hypoxia when induced\n",
    "    -  Rv0081  - part of the initial hypoxic response, regulon also has large overlap with hypoxic response\n",
    "    -  Rv0353  - HspR, regulator of the heat shock protein chaperones\n",
    "    -  Rv1985c - Several proposed functions for this TF, none confirmed yet, deleted in the vaccine strain BCG\n",
    "    -  Rv2788  - SirR, suggested role as regulator of manganese homeostasis and other stress responses\n",
    "    -  Rv3416  - WhiB3, redox homeostasis regulator, described in multiple papers from Adrie Steyn\n",
    "    -  Empty   - This strain carrys the same plasmid as the others, but there is no TF inserted\n",
    "\n",
    " - Hypoxia: Each strain was taken through a hypoxic time course that begins with log phase growth to hypoxia and reaeration\n",
    "    -  Log\n",
    "    -  Hypoxia\n",
    "    -  Reaeration\n",
    "\n",
    " - Time: After the day 0 sample is taken the culuture is transfered to a flask that has a steady flow of nitrogen with 0.2% oxygen, roughly 1% of atmospheric.\n",
    "    -  Day 0  - Log phase culture\n",
    "    -  Day 2  - Hypoxia\n",
    "    -  Day 4  - Hypoxia\n",
    "    -  Day 7  - Hypoxia. Culture transfered to aerobic rolling flask\n",
    "    -  Day 8  - Reaeration\n",
    "    -  Day 9  - Reaeration\n",
    "    -  Day 10 - Reaeration\n",
    "    -  Day 11 - Reaeration\n",
    "    -  Day 12 - Reaeration. Not present for some strains\n",
    "\n",
    "\n",
    "#### More detail for people with less background in TB research and our prior experiments\n",
    "\n",
    "The strains used in this experiment were made as part of a previous project. They all come from the lab strain H37Rv, often abbreviated 'Rv', and each strain is carrying a plasmid that allows us to induce the overexpression of one of the CORRs. These plasmids have the TF gene downstream of a strong promoter and the TetO operator, which is recognized by the TetR repressor. In the presence of the inducer (anhydrotetracycline or Atc) TetR is removed from the promoter and these strains begin expressing that TF from the plasmid in addition to the native copy in the genome. These TFs have varying levels of baseline expression, but in all cases the given TF becomes one of the most highly expressed genes in the genome. \n",
    "\n",
    "Also note that these TFs have been modified so that they carry a FLAG tag on their C' tail. We don't haven't found an example where the tail has any impact on the TF function, but it is certainly possible that in some cases that extra bit will interfere or modify DNA binding properties. Note- the FLAG tag was used in ChIP experiments to determine the DNA binding profile of each TF.\n",
    "\n",
    "Transcription factors typically change their promoter affinity based on some secondary signal like a small molecule, modifications to the TF by another protein (e.g. phosphorylation by a kinase), or interaction with a partner protein. In this case however we are driving activation of these TFs by mass action, simply overcoming the weak interaction of the TF without the activating signal by generating an excess of TF, some of which will bind to and activate that gene's regulon. \n",
    "\n",
    "Activation of TFs by overexpression could lead to binding and activation of genes not normally regulated by that TF. It's also possible that the the TF may have some impact on the cell other than DNA binding, and these effects could lead to changes in gene expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Python-setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Import python libraries and initialize global style settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all required python libraries\n",
    "\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from clustergrammer2 import net\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn    \n",
    "import scipy      \n",
    "import numpy\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## style settings for seaborn, pylab, and matplotlib\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "## set so figures show up in the notebook just below the code block\n",
    "%matplotlib inline\n",
    "\n",
    "## limit output to 20 lines\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data-import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "In the future I'd like to add the ability to start with raw FASTQ files straight from the sequencers, but that'll take time and I'd rather finish a working version of this notebook first, so we will start with data that has been processed to generate read counts for each gene.\n",
    "\n",
    "We start by loading the RNAseq data into a pandas data frame. Remember that the data being imported __must__ be in 'tidy' format, which makes the importing part so smooth. The python library 'pandas' is is a very useful way of storing data in spreadsheet-like 'panel data', thus the name. Then we will break this table into a subtable with just data and a subtable with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data from a csv file and use the first row as indices, or row names\n",
    "df = pd.read_csv(\"./data/CORRtable.csv\", index_col=0)\n",
    "\n",
    "## use the name of the first column of data to find its index\n",
    "FIRST_DATA_COL = df.columns.get_loc('Rv0001')\n",
    "\n",
    "## Check the size and show a sample of the imported data\n",
    "sample_num, obs_num = df.shape\n",
    "print (f\"This data set is comprised of {sample_num} RNAseq samples, each with {obs_num} variables\")\n",
    "df.iloc[:5,:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The first three columns of data contain meta-information about these samples (Strain, Day, and Oxygen) and the remaining columns show the count of reads that align to the given gene per million reads total, or CPM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on we will want to refer to just the data or just the metadata, so let's create those subtables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the 'df' dataframe into data and metadata\n",
    "data = df.iloc[:,FIRST_DATA_COL:]\n",
    "meta = df.iloc[:,:FIRST_DATA_COL]\n",
    "\n",
    "## take a look at the resulting tables to make sure they look right.\n",
    "print (\"Data table shape:\",data.shape)\n",
    "print (\"Meta(data) table shape:\",meta.shape)\n",
    "\n",
    "meta.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Colors'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up color palettes\n",
    "\n",
    "Now we inspect each column of metadata, look at how the data groups, and create a custom color palette for each type of metadata that we can use a consistent color scheme for all of the plots below.  \n",
    "\n",
    "We first create vectors containing each element of metadata for use as categories and set up a color palette for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## for each metadata column create a list with each variable for each sample and a list with all unique values\n",
    "strain = df['Strain']\n",
    "unique_strain = np.unique(strain)\n",
    "day = df['Day']\n",
    "unique_day = np.unique(day)\n",
    "oxygen = df['Oxygen']\n",
    "unique_oxygen = np.unique(oxygen)\n",
    "\n",
    "## print out the list of unique meta-data values\n",
    "print(unique_strain)\n",
    "print(unique_day)\n",
    "print(unique_oxygen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assign colors to each unique value to make it easier to have consistent plots. I've made two ways to set the colors. You can either go with the preset palette's below or use interactive sliders to set the colors to your liking. Keep in mind that if you run a second one of these code boxes you will overwrite the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interactive selection of palettes\n",
    "\n",
    "## strain palette\n",
    "print(f\"You'll want to set the number of colors to the number of unique strains: _{len(unique_strain)}_.\")\n",
    "strain_pal = sns.choose_colorbrewer_palette('q')\n",
    "\n",
    "## day palette\n",
    "print(f\"You'll want to set the number of colors to the number of timepoints sampled _{len(unique_day)}_.\")\n",
    "day_pal = sns.choose_colorbrewer_palette('q')\n",
    "\n",
    "## oxygen palette\n",
    "print(f\"You'll want to set the number of colors to _{len(unique_oxygen)}_.\")\n",
    "oxygen_pal = sns.choose_colorbrewer_palette('q')\n",
    "\n",
    "## lastly lets pick out a color scheme for the heatmap\n",
    "print(\"Heatmap color spectrum\")\n",
    "hmap_col = sns.choose_cubehelix_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternative static selection of palettes\n",
    "## **this will overwrite the interactive palette!**\n",
    "## if you're curious about other colors from this palette you can find them all here : https://xkcd.com/color/rgb/\n",
    "\n",
    "## strain palette\n",
    "strain_pal = sns.color_palette(\"Set1\",len(unique_strain))\n",
    "\n",
    "## day palette\n",
    "day_pal = sns.color_palette(\"Set2\",len(unique_day))\n",
    "\n",
    "## oxygen palette\n",
    "oxygen_pal = sns.xkcd_palette([\"windows blue\", \"amber\", \"dusty purple\"])\n",
    "\n",
    "## heatmap palette\n",
    "hmap_col = sns.cubehelix_palette(8, start=.5, rot=-.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's make a function that plots a quick barplot showing each value and the color assigned to it\n",
    "def paltest (values, test_pal):\n",
    "    paltest = pd.DataFrame(index = values)\n",
    "    paltest['test']=1\n",
    "    #plt.subplots(figsize = (1,len(values)))\n",
    "    sns.barplot(y=paltest.index, x=paltest.test, palette = test_pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show each palette \n",
    "## there is a bug somewhere preventing me from plotting these side by side \n",
    "\n",
    "paltest(unique_strain,strain_pal)\n",
    "paltest(unique_day,day_pal)\n",
    "paltest(unique_oxygen,oxygen_pal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show each palette \n",
    "## there is a bug somewhere preventing me from plotting these side by side \n",
    "f, ax = plt.subplots(1,3)\n",
    "ax1, ax2, ax3 = ax.flatten()\n",
    "ax1 = paltest(unique_strain,strain_pal)\n",
    "ax2 = paltest(unique_day,day_pal)\n",
    "ax3 = paltest(unique_oxygen,oxygen_pal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## once color map is selected, we make a 'look-up-table' that tells us what color to map to each value\n",
    "## then use that lut to map each color back to the matching strains.\n",
    "strain_lut = dict(zip(unique_strain, strain_pal))\n",
    "strain_cols = pd.Series(strain).map(strain_lut)\n",
    "\n",
    "day_lut = dict(zip(unique_day, day_pal))\n",
    "day_cols = pd.Series(day).map(day_lut)\n",
    "\n",
    "oxygen_lut = dict(zip(unique_oxygen, oxygen_pal))\n",
    "oxygen_cols = pd.Series(oxygen).map(oxygen_lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Sanity-check'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check- does the data look 'right'\n",
    "\n",
    "The first thing I do with any dataset like this is do a sanity check to see if the data looks like I expect, given the experimental design. First we'll check how well the replicates cluster using heatmaps and PCA to get two different views of the same data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the distance matrix \n",
    "dists = pdist(data, 'correlation')\n",
    "\n",
    "## take those distances and convert the vector into a square \n",
    "col_ident_mat = pd.DataFrame(squareform(dists), index=df.index, columns=df.index)\n",
    "\n",
    "## make a single table with all of the metadata colors together to use as the label colors\n",
    "colors = pd.DataFrame(strain_cols).join(pd.DataFrame(day_cols)).join(pd.DataFrame(oxygen_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot out all of the samples in a single identity correlation map\n",
    "g = sns.clustermap(col_ident_mat,\n",
    "                   # Turn off the clustering\n",
    "                   row_cluster=False, col_cluster=False,\n",
    "\n",
    "                   # Add colored class labels\n",
    "                   row_colors = colors,\n",
    "                   col_colors = colors,\n",
    "                   # Make the plot look better when many rows/cols\n",
    "                   linewidths=0, xticklabels=False, yticklabels=False,\n",
    "\n",
    "                   # use the color scheme selected above for the heatmap\n",
    "                   cmap = hmap_col\n",
    "                  )\n",
    "## draw the legend bar for the classes                 \n",
    "for label in df['Day'].unique():\n",
    "    g.ax_col_dendrogram.bar(0, 0, color=day_lut[label],\n",
    "                            label=label, linewidth=0)\n",
    "\n",
    "l1 = g.ax_col_dendrogram.legend(title='Day', loc=\"center\", ncol=5, bbox_to_anchor=(0.2, 0.6))    \n",
    "\n",
    "for label in df['Strain'].unique():\n",
    "    g.ax_row_dendrogram.bar(0, 0, color=strain_lut[label],\n",
    "                            label=label, linewidth=0)\n",
    "\n",
    "l2 = g.ax_row_dendrogram.legend(title='Strain', loc=\"right\", ncol=2, bbox_to_anchor=(6, 1.2))\n",
    "    \n",
    "## adjust the postion of the main colorbar for the heatmap\n",
    "g.cax.set_position([1, .2, .03, .45])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little too busy to see clearly, so we will break this up into seperate correlation matrices for each strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = pd.DataFrame(day_cols).join(pd.DataFrame(oxygen_cols))\n",
    "for ustrain in unique_strain:\n",
    "    sset = df.loc[df['Strain']== ustrain]\n",
    "    ## generate the distance matrix, slicing off the metadata \n",
    "    ssdists = pdist(sset.iloc[:,FIRST_DATA_COL:], 'correlation')\n",
    "    col_ident_mat = pd.DataFrame(squareform(ssdists), index=sset.index)\n",
    "   \n",
    "    g = sns.clustermap(col_ident_mat,\n",
    "                   # Turn off the clustering\n",
    "                   row_cluster=False, col_cluster=False,\n",
    "\n",
    "                   # Add colored class labels\n",
    "                   row_colors = colors,                        \n",
    "                   # Make the plot look better when many rows/cols\n",
    "                   linewidths=0, xticklabels=False, yticklabels=True,\n",
    "\n",
    "                   # use the color scheme selected above for the heatmap\n",
    "                   cmap = hmap_col\n",
    "                      )\n",
    "    plt.title(ustrain)\n",
    "    g.cax.set_position([.1, .3, .03, .45])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the replicates look like each other, the log phase looks like reaeration, and the hypoxic timepoints look like each other. There are other interesting patterns here. Look at the plot for the strain overexpressing Rv3416, just above. Notice the banding pattern in the reaeration samples. It looks like one of the replicates (R2) has reaeration expression profiles that look more like hypoxia than the other replicates. We could eliminate that sample as an outlier, but for now I will leave it there and just keep that variation in mind when interpreting the data below.\n",
    "\n",
    "Now let's collapse the replicates, and then convert to log base 2. Why do I do this? Expression data has a log-normal distribution, so it's simpler to plot and understand the data in a log scale. There is nothing magical about a two-fold difference of course, but in my experience even under the best of conditions with minimal noise changes less than two fold are rarely significant. So, having log base 2 means that we can easily see two fold steps in expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average replicates, convert to log base 2, and round to two significant digits\n",
    "logdata = df.groupby(['Strain', 'Day']).mean()\n",
    "logdata = np.log2(logdata)\n",
    "logdata = np.round(logdata, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## when you add a '.loc' to the end of a Dataframe you pull data from a specific location\n",
    "## here I want the expression of the gene Rv0023, and \n",
    "## I want to see that gene's expression over time in the Empty Plasmid and Rv0023 overexpressing strains\n",
    "logdata.loc[['EmptyPlasmid','Rv0023'],'Rv0023'].unstack()\n",
    "## the .unstack() makes the data easier to read- try it with and without if you'd like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive heatmap - Clustergrammer\n",
    "\n",
    "This tool by the Ma'ayan lab creates a heatmap that is amazingly easy to use. At least on my computer it has problems with looking at more than a dozen arrays at a time, so here I'll first collapse the replicates and then use Clustergrammer to look at the genes with the largest differences between samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(net.filter_N_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_df(logdata)\n",
    "#net.load_file('./data/CORRtable2.txt')       # this file is in the 'clustergrammer' format and lets me skip the data munging \n",
    "\n",
    "net.filter_N_top(inst_rc='row', N_top=200, rank_type='var')\n",
    "net.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df in Clustergrammer format\n",
    "df2 = df.T\n",
    "newlabs = df2.loc['Oxygen',:].add_prefix('Oxygen: ')\n",
    "df2.loc['Oxygen',:]=newlabs\n",
    "# check the size and type of the imported data\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize values to z-scores (i.e. how many st dev from the mean)\n",
    "net.normalize(axis='row', norm_type='zscore')\n",
    "\n",
    "# cluster using default parameters\n",
    "net.widget()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot to get another view of sample clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will generate a PCA plot to collapse all of the gene expression values (dimensions) in a way that maximizes difference between samples\n",
    "time_start = time.time()\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca_result = pca.fit_transform(logdata)\n",
    "elapsed = time.time()-time_start\n",
    "print (\"PCA done! Time elapsed:\",elapsed,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function to plot the data from PCA (and later tSNE) plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect the PCA data into a new data frame for plotting and calculate how much of the sample variance can be described by each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(columns = ['pca1','pca2','pca3','pca4'])\n",
    "\n",
    "pca_df['pca1'] = pca_result[:,0]\n",
    "pca_df['pca2'] = pca_result[:,1]\n",
    "pca_df['pca3'] = pca_result[:,2]\n",
    "pca_df['pca4'] = pca_result[:,3]\n",
    "\n",
    "print (\"Variance explained per principal component: \", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn the indices of the logdata table into columns of metadata\n",
    "logmeta = logdata.reset_index().iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_two_comp = pca_df[['pca1','pca2']] # taking first and second principal component\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(x = pca_df['pca1'], y = pca_df['pca2'], hue = logmeta['Day']) # Visualizing the PCA output\n",
    "plt.subplot(122)\n",
    "sns.scatterplot(x = pca_df['pca1'], y = pca_df['pca2'], hue = logmeta['Strain']) # Visualizing the PCA output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
